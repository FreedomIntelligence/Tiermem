"""
LongMemEvalæ•°æ®é›†åŠ è½½å™¨

å‚è€ƒå®ç°ï¼š
- LongMemEval/src/generation/run_generation.py
- LongMemEval/src/retrieval/run_retrieval.py
- EverMemOS/evaluation/src/converters/longmemeval_converter.py

æ•°æ®æ ¼å¼ï¼š
- æ¯ä¸ªæ ·æœ¬åŒ…å«ä¸€ä¸ªé—®é¢˜åŠå…¶ç›¸å…³çš„å†å²å¯¹è¯ï¼ˆhaystack_sessionsï¼‰
- haystack_sessions: åŒ…å«å¤šä¸ªsessionï¼Œæ¯ä¸ªsessionåŒ…å«å¤šä¸ªturnï¼ˆroleå’Œcontentï¼‰
- é—®é¢˜ç±»å‹åŒ…æ‹¬ï¼šsingle-session-user, single-session-assistant, multi-session, 
  temporal-reasoning, knowledge-update, single-session-preference

å…³é”®è®¾è®¡ï¼šåŒæ—¶æä¾›ä¸¤ç§ç²’åº¦çš„turns
- "turns": ç»†ç²’åº¦ï¼Œé€turnå¯¹è¯ï¼ˆç»™Mem0/LightMem/MIRIX/RAW+LLMç”¨ï¼‰
- "session_chunks": ç²—ç²’åº¦ï¼ŒæŒ‰sessionç»„ç»‡çš„chunkï¼ˆç»™GAMç”¨ï¼‰

å…³é”®ç‰¹æ€§ï¼ˆå‚è€ƒEverMemOSå®ç°ï¼‰ï¼š
- æ ‡è®°åŒ…å«ç­”æ¡ˆçš„turnsï¼ˆhas_answerå­—æ®µï¼‰
- ç”Ÿæˆevidenceåˆ—è¡¨ï¼ˆæ ¼å¼ï¼šD{session_idx}:{turn_idx}ï¼‰
- åœ¨QA pairsä¸­åŒ…å«evidenceå’Œcategoryä¿¡æ¯

ç³»ç»Ÿå¯ä»¥é€šè¿‡preferred_turns_keyå±æ€§é€‰æ‹©ä½¿ç”¨å“ªä¸ªç²’åº¦

è½¬æ¢åŠŸèƒ½ï¼š
- convert_to_locomo_style: å°†LongMemEvalæ ¼å¼è½¬æ¢ä¸ºLoCoMoæ ¼å¼ï¼ˆå‚è€ƒEverMemOSå®ç°ï¼‰
"""
import json
import re
from typing import Dict, Any, List, Optional, Iterator, Tuple
from pathlib import Path
from datetime import datetime
import os

# å°è¯•å¯¼å…¥ tiktoken ç”¨äº token çº§åˆ«çš„ chunking
try:
    import tiktoken
    TIKTOKEN_AVAILABLE = True
except ImportError:
    TIKTOKEN_AVAILABLE = False
    tiktoken = None


def load_longmemeval_json(json_path: str) -> List[Dict[str, Any]]:
    """
    åŠ è½½LongMemEval JSONæ–‡ä»¶
    
    Args:
        json_path: JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ ·æœ¬åˆ—è¡¨
    """
    # å°è¯•ä½œä¸ºJSONæ•°ç»„åŠ è½½
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            return data
        if isinstance(data, dict) and "samples" in data:
            return data["samples"]
        raise ValueError("Unrecognized LongMemEval JSON shape. Expect a list or {'samples': [...]}.")
    except json.JSONDecodeError:
        # å¦‚æœæ•´ä¸ªæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•æŒ‰è¡Œè¯»å–ï¼ˆJSONLæ ¼å¼ï¼‰
        samples = []
        with open(json_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        samples.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
        return samples


def session_to_text(session_id: str, session_date: str, turns: List[Dict[str, Any]]) -> str:
    """
    å°†sessionè½¬æ¢ä¸ºæ–‡æœ¬å—ï¼ˆç±»ä¼¼GAMçš„æ–¹å¼ï¼‰
    
    Args:
        session_id: session ID
        session_date: sessionæ—¥æœŸ
        turns: sessionä¸­çš„turnsåˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–çš„æ–‡æœ¬å—
    """
    dia_id = turns[0].get("dia_id", "") if turns else ""
    lines = [f"=== SESSION {session_id} - Date: {session_date} - Dia ID: {dia_id} ==="]
    lines.append("")  # ç©ºè¡Œåˆ†éš”
    
    for turn in turns:
        role = turn.get("role", "unknown")
        content = turn.get("content", "")
        if content:
            lines.append(f"{role}: {content}")
    
    return "\n".join(lines).strip()


def _get_encoding(encoding_model: str = "gpt-4o-mini"):
    """è·å– tiktoken ç¼–ç å™¨"""
    if not TIKTOKEN_AVAILABLE:
        return None
    
    try:
        return tiktoken.encoding_for_model(encoding_model)
    except Exception:
        try:
            return tiktoken.get_encoding(encoding_model)
        except Exception:
            return tiktoken.get_encoding("cl100k_base")


def _count_tokens(text: str, encoding_model: str = "gpt-4o-mini") -> int:
    """
    è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡
    
    Args:
        text: è¦è®¡ç®—çš„æ–‡æœ¬
        encoding_model: ç”¨äº token ç¼–ç çš„æ¨¡å‹åç§°
        
    Returns:
        token æ•°é‡
    """
    encoding = _get_encoding(encoding_model)
    if encoding is None:
        # å¦‚æœæ²¡æœ‰ tiktokenï¼Œç²—ç•¥ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 å­—ç¬¦ï¼‰
        return len(text) // 4
    
    try:
        tokens = encoding.encode(text, allowed_special={"<|endoftext|>"})
        return len(tokens)
    except Exception:
        try:
            tokens = encoding.encode(text, disallowed_special=())
            return len(tokens)
        except Exception:
            # å¦‚æœéƒ½å¤±è´¥ï¼Œå›é€€åˆ°å­—ç¬¦ä¼°ç®—
            return len(text) // 4


def _get_encoding(encoding_model: str = "gpt-4o-mini"):
    """è·å– tiktoken ç¼–ç å™¨"""
    if not TIKTOKEN_AVAILABLE:
        return None
    
    try:
        return tiktoken.encoding_for_model(encoding_model)
    except Exception:
        try:
            return tiktoken.get_encoding(encoding_model)
        except Exception:
            return tiktoken.get_encoding("cl100k_base")


def _count_tokens(text: str, encoding_model: str = "gpt-4o-mini") -> int:
    """
    è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡
    
    Args:
        text: è¦è®¡ç®—çš„æ–‡æœ¬
        encoding_model: ç”¨äº token ç¼–ç çš„æ¨¡å‹åç§°
        
    Returns:
        token æ•°é‡
    """
    encoding = _get_encoding(encoding_model)
    if encoding is None:
        # å¦‚æœæ²¡æœ‰ tiktokenï¼Œç²—ç•¥ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 å­—ç¬¦ï¼‰
        return len(text) // 4
    
    try:
        tokens = encoding.encode(text, allowed_special={"<|endoftext|>"})
        return len(tokens)
    except Exception:
        try:
            tokens = encoding.encode(text, disallowed_special=())
            return len(tokens)
        except Exception:
            # å¦‚æœéƒ½å¤±è´¥ï¼Œå›é€€åˆ°å­—ç¬¦ä¼°ç®—
            return len(text) // 4


def _format_turn_locomo(turn: Dict[str, Any]) -> str:
    """å°†å•ä¸ª turn æ ¼å¼åŒ–ä¸ºæ–‡æœ¬ï¼ˆLoCoMo æ ¼å¼ï¼‰"""
    speaker = turn.get("speaker", "Unknown")
    dia_id = turn.get("dia_id", "")
    text = turn.get("text", "")
    blip_caption = turn.get("blip_caption", "")
    if blip_caption:
        return f"{speaker} ({dia_id}): {text} (blip_caption: {blip_caption})"
    else:
        return f"{speaker} ({dia_id}): {text}"


def _format_turn_original(turn: Dict[str, Any]) -> str:
    """å°†å•ä¸ª turn æ ¼å¼åŒ–ä¸ºæ–‡æœ¬ï¼ˆåŸå§‹ LongMemEval æ ¼å¼ï¼‰"""
    role = turn.get("role", "unknown")
    content = turn.get("content", "")
    return f"{role}: {content}" if content else ""


def _chunk_sessions_with_turns_locomo(
    sessions: List[Tuple[int, str, List[Dict[str, Any]], Optional[str]]],
    chunk_size: int,
    encoding_model: str = "gpt-4o-mini"
) -> List[str]:
    """
    æŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶
    
    é€»è¾‘ï¼š
    1. ä¿æŒ session è¾¹ç•Œï¼ˆæ¯ä¸ª chunk åªåŒ…å«ä¸€ä¸ª session çš„å†…å®¹ï¼‰
    2. åœ¨ session å†…éƒ¨ï¼ŒæŒ‰å¯¹è¯ï¼ˆturnï¼‰åˆå¹¶
    3. å¦‚æœå½“å‰ chunk åŠ ä¸Šä¸‹ä¸€ä¸ª turn ä¸è¶…è¿‡ chunk_sizeï¼Œå°±åˆå¹¶
    4. å¦‚æœè¶…è¿‡ï¼Œå°±åˆ›å»ºæ–°çš„ chunkï¼ˆä½†ä»åœ¨åŒä¸€ä¸ª session å†…ï¼‰
    
    Args:
        sessions: session åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (idx, timestamp, turns, session_summary)
        chunk_size: æ¯ä¸ª chunk çš„æœ€å¤§ token æ•°é‡
        encoding_model: ç”¨äº token ç¼–ç çš„æ¨¡å‹åç§°
        
    Returns:
        chunk æ–‡æœ¬åˆ—è¡¨
    """
    chunks: List[str] = []
    
    for session_idx, ts, turns, ssum in sessions:
        # Session å¤´éƒ¨
        session_header = f"=== SESSION {session_idx} - Dialogue Time(available to answer questions): {ts} ===\n"
        header_tokens = _count_tokens(session_header, encoding_model)
        
        # å½“å‰ chunk çš„å†…å®¹å’Œ token æ•°
        current_chunk_lines: List[str] = []
        current_chunk_tokens = header_tokens
        
        for turn_idx, turn in enumerate(turns):
            turn_text = _format_turn_locomo(turn)
            turn_tokens = _count_tokens(turn_text, encoding_model)
            
            # å¦‚æœå½“å‰ chunk ä¸ºç©ºï¼Œå…ˆæ·»åŠ  session å¤´éƒ¨
            if not current_chunk_lines:
                current_chunk_lines.append(session_header.rstrip())
                current_chunk_tokens = header_tokens
            
            # æ£€æŸ¥åŠ ä¸Šè¿™ä¸ª turn æ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
            if current_chunk_tokens + turn_tokens <= chunk_size:
                # å¯ä»¥åˆå¹¶
                current_chunk_lines.append(turn_text)
                current_chunk_tokens += turn_tokens
            else:
                # è¶…è¿‡é™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰ chunkï¼ˆä¸æ·»åŠ  summaryï¼Œå› ä¸ºå¯èƒ½è¿˜æœ‰æ›´å¤š turnsï¼‰
                if current_chunk_lines:
                    chunks.append("\n".join(current_chunk_lines))
                
                # å¼€å§‹æ–°çš„ chunkï¼ˆä»å±äºåŒä¸€ä¸ª sessionï¼‰
                current_chunk_lines = [session_header.rstrip(), turn_text]
                current_chunk_tokens = header_tokens + turn_tokens
        
        # ä¿å­˜æœ€åä¸€ä¸ª chunkï¼Œå¹¶æ·»åŠ  session summaryï¼ˆå¦‚æœæœ‰ï¼‰
        if current_chunk_lines:
            if ssum:
                current_chunk_lines.append("")
                current_chunk_lines.append(f"Session {session_idx} summary: {ssum}")
            chunks.append("\n".join(current_chunk_lines))
    
    return chunks


def _chunk_sessions_with_turns_original(
    haystack_dates: List[str],
    haystack_session_ids: List[str],
    haystack_sessions: List[List[Dict[str, Any]]],
    chunk_size: int,
    encoding_model: str = "gpt-4o-mini"
) -> List[str]:
    """
    æŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶ï¼ˆåŸå§‹ LongMemEval æ ¼å¼ï¼‰
    
    é€»è¾‘åŒ _chunk_sessions_with_turns_locomo
    """
    chunks: List[str] = []
    
    for session_idx, (session_date, session_id, session_entry) in enumerate(
        zip(haystack_dates, haystack_session_ids, haystack_sessions)
    ):
        if not isinstance(session_entry, list):
            session_entry = [session_entry]
        
        # Session å¤´éƒ¨
        dia_id = session_entry[0].get("dia_id", "") if session_entry else ""
        session_header = f"=== SESSION {session_id} - Date: {session_date} - Dia ID: {dia_id} ===\n"
        header_tokens = _count_tokens(session_header, encoding_model)
        
        # å½“å‰ chunk çš„å†…å®¹å’Œ token æ•°
        current_chunk_lines: List[str] = []
        current_chunk_tokens = 0
        
        for turn in session_entry:
            turn_text = _format_turn_original(turn)
            if not turn_text:  # è·³è¿‡ç©ºå†…å®¹
                continue
            
            turn_tokens = _count_tokens(turn_text, encoding_model)
            
            # å¦‚æœå½“å‰ chunk ä¸ºç©ºï¼Œå…ˆæ·»åŠ  session å¤´éƒ¨
            if not current_chunk_lines:
                current_chunk_lines.append(session_header.rstrip())
                current_chunk_tokens = header_tokens
            
            # æ£€æŸ¥åŠ ä¸Šè¿™ä¸ª turn æ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
            if current_chunk_tokens + turn_tokens <= chunk_size:
                # å¯ä»¥åˆå¹¶
                current_chunk_lines.append(turn_text)
                current_chunk_tokens += turn_tokens
            else:
                # è¶…è¿‡é™åˆ¶ï¼Œå…ˆä¿å­˜å½“å‰ chunk
                if current_chunk_lines:
                    chunks.append("\n".join(current_chunk_lines))
                
                # å¼€å§‹æ–°çš„ chunkï¼ˆä»å±äºåŒä¸€ä¸ª sessionï¼‰
                current_chunk_lines = [session_header.rstrip(), turn_text]
                current_chunk_tokens = header_tokens + turn_tokens
        
        # ä¿å­˜æœ€åä¸€ä¸ª chunk
        if current_chunk_lines:
            chunks.append("\n".join(current_chunk_lines))
    
    return chunks


def _chunk_text_by_tokens(text: str, chunk_size: int, encoding_model: str = "gpt-4o-mini") -> List[str]:
    """
    æŒ‰ token æ•°é‡åˆ‡åˆ†æ–‡æœ¬ï¼ˆå‚è€ƒ memr3 çš„å®ç°ï¼‰
    
    Args:
        text: è¦åˆ‡åˆ†çš„æ–‡æœ¬
        chunk_size: æ¯ä¸ª chunk çš„ token æ•°é‡ï¼ˆ-1 è¡¨ç¤ºä¸åˆ‡åˆ†ï¼‰
        encoding_model: ç”¨äº token ç¼–ç çš„æ¨¡å‹åç§°
        
    Returns:
        åˆ‡åˆ†åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if chunk_size == -1:
        return [text]
    
    encoding = _get_encoding(encoding_model)
    if encoding is None:
        # å¦‚æœæ²¡æœ‰ tiktokenï¼Œå›é€€åˆ°æŒ‰å­—ç¬¦æ•°ç²—ç•¥ä¼°ç®—ï¼ˆ1 token â‰ˆ 4 å­—ç¬¦ï¼‰
        char_size = chunk_size * 4
        chunks = []
        for i in range(0, len(text), char_size):
            chunks.append(text[i:i + char_size])
        return chunks
    
    # ç¼–ç æ—¶å…è®¸ç‰¹æ®Š tokenï¼Œé¿å…é‡åˆ° <|endoftext|> ç­‰ç‰¹æ®Š token æ—¶æŠ¥é”™
    try:
        tokens = encoding.encode(text, allowed_special={"<|endoftext|>"})
    except Exception:
        # å¦‚æœä»ç„¶å¤±è´¥ï¼Œå°è¯•ç¦ç”¨æ‰€æœ‰ç‰¹æ®Š token æ£€æŸ¥
        tokens = encoding.encode(text, disallowed_special=())
    
    chunks: List[str] = []
    for i in range(0, len(tokens), chunk_size):
        chunk_tokens = tokens[i : i + chunk_size]
        chunk = encoding.decode(chunk_tokens)
        chunks.append(chunk)
    
    return chunks


def build_session_chunks_for_sample(sample: Dict[str, Any], chunk_size: Optional[int] = None) -> List[str]:
    """
    ä¸ºsampleæ„å»ºsession chunksï¼ˆç²—ç²’åº¦ï¼Œç»™GAMç”¨ï¼‰
    
    Args:
        sample: æ ·æœ¬å­—å…¸
        chunk_size: å¦‚æœæä¾›ï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶ï¼ˆä¸è¶…è¿‡ chunk_size tokensï¼‰ï¼›
                   å¦‚æœä¸º Noneï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼ˆæ¯ä¸ª session ä¸€ä¸ª chunkï¼‰
        
    Returns:
        session chunksæ–‡æœ¬åˆ—è¡¨
    """
    haystack_dates = sample.get("haystack_dates", [])
    haystack_session_ids = sample.get("haystack_session_ids", [])
    haystack_sessions = sample.get("haystack_sessions", [])
    
    # å¦‚æœæŒ‡å®šäº† chunk_sizeï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶
    if chunk_size is not None:
        return _chunk_sessions_with_turns_original(
            haystack_dates, haystack_session_ids, haystack_sessions, chunk_size
        )
    
    # å¦åˆ™æŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼ˆåŸæœ‰é€»è¾‘ï¼Œæ¯ä¸ª session ä¸€ä¸ª chunkï¼‰
    chunks: List[str] = []
    for session_date, session_id, session_entry in zip(haystack_dates, haystack_session_ids, haystack_sessions):
        if isinstance(session_entry, list):
            chunks.append(session_to_text(session_id, session_date, session_entry))
        else:
            # å¦‚æœsession_entryä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•è½¬æ¢
            chunks.append(session_to_text(session_id, session_date, [session_entry]))
    
    return chunks


def _is_locomo_format(sample: Dict[str, Any]) -> bool:
    """
    æ£€æµ‹æ•°æ®æ ·æœ¬æ˜¯å¦æ˜¯ LoCoMo æ ¼å¼
    
    LoCoMo æ ¼å¼ç‰¹å¾ï¼š
    - æœ‰ "conversation" å­—æ®µï¼Œä¸”åŒ…å« "session_0", "session_0_date_time" ç­‰
    - æœ‰ "qa" å­—æ®µï¼Œä¸”æ˜¯åˆ—è¡¨æ ¼å¼
    
    Args:
        sample: æ•°æ®æ ·æœ¬
        
    Returns:
        True å¦‚æœæ˜¯ LoCoMo æ ¼å¼ï¼ŒFalse å¦‚æœæ˜¯åŸå§‹ LongMemEval æ ¼å¼
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰ conversation å­—æ®µä¸”åŒ…å« session_* é”®
    conv = sample.get("conversation", {})
    if isinstance(conv, dict):
        # æ£€æŸ¥æ˜¯å¦æœ‰ session_0, session_1 ç­‰é”®
        has_session_keys = any(re.match(r'^session_\d+$', k) for k in conv.keys())
        if has_session_keys:
            return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹ LongMemEval æ ¼å¼çš„ç‰¹å¾
    if "haystack_sessions" in sample and "question" in sample:
        return False
    
    # é»˜è®¤å‡è®¾æ˜¯ LoCoMo æ ¼å¼ï¼ˆå¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯å…¶ä»–æ ¼å¼ï¼‰
    return True


def extract_sessions(conv_obj: Dict[str, Any]) -> List[Tuple[int, str, List[Dict[str, Any]], Optional[str]]]:
    """
    ä»conversationå¯¹è±¡ä¸­æå–sessionsï¼ˆå‚è€ƒ locomo.py çš„å®ç°ï¼‰
    
    Returns:
        List of (idx, timestamp, turns, session_summary)
    """
    sessions: List[Tuple[int, str, List[Dict[str, Any]], Optional[str]]] = []
    for k, v in conv_obj.items():
        m = re.match(r'^session_(\d+)$', k)
        if not (m and isinstance(v, list)):
            continue
        original_idx = int(m.group(1))
        idx = original_idx - 1
        ts = conv_obj.get(f"session_{original_idx}_date_time", "")
        ssum = conv_obj.get(f"session_{original_idx}_summary", None)
        sessions.append((
            idx, 
            ts, 
            v, 
            ssum if isinstance(ssum, str) and ssum.strip() else None
        ))
    sessions.sort(key=lambda x: x[0])
    return sessions


def session_to_text_locomo(idx: int, ts: str, turns: List[Dict[str, Any]], session_summary: Optional[str]) -> str:
    """
    å°†sessionè½¬æ¢ä¸ºæ–‡æœ¬å—ï¼ˆå‚è€ƒ locomo.py çš„å®ç°ï¼Œç”¨äº LoCoMo æ ¼å¼ï¼‰
    
    å…³é”®ï¼šåŒ…å«æ—¶é—´ä¿¡æ¯ã€speakerã€dia_idç­‰ï¼Œæ ¼å¼ä¸å®˜æ–¹ä¸€è‡´
    """
    lines = [f"=== SESSION {idx} - Dialogue Time(available to answer questions): {ts} ==="]
    lines.append("")  # ç©ºè¡Œåˆ†éš”
    
    for turn in turns:
        speaker = turn.get("speaker", "Unknown")
        dia_id = turn.get("dia_id", "")
        text = turn.get("text", "")
        blip_caption = turn.get("blip_caption", "")
        if blip_caption:    
            lines.append(f"{speaker} ({dia_id}): {text} (blip_caption: {blip_caption})")
        else:
            lines.append(f"{speaker} ({dia_id}): {text}")
    
    if session_summary:
        lines.append("")
        lines.append(f"Session {idx} summary: {session_summary}")
    
    return "\n".join(lines).strip()


def build_session_chunks_for_locomo_sample(sample: Dict[str, Any], chunk_size: Optional[int] = None) -> List[str]:
    """
    ä¸º LoCoMo æ ¼å¼çš„ sample æ„å»º session chunksï¼ˆå‚è€ƒ locomo.py çš„å®ç°ï¼‰
    
    Args:
        sample: æ ·æœ¬å­—å…¸
        chunk_size: å¦‚æœæä¾›ï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶ï¼ˆä¸è¶…è¿‡ chunk_size tokensï¼‰ï¼›
                   å¦‚æœä¸º Noneï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼ˆæ¯ä¸ª session ä¸€ä¸ª chunkï¼‰
    """
    conv = sample.get("conversation", {})
    sessions = extract_sessions(conv)
    
    # å¦‚æœæŒ‡å®šäº† chunk_sizeï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼Œsession å†…éƒ¨æŒ‰å¯¹è¯åˆå¹¶
    if chunk_size is not None:
        return _chunk_sessions_with_turns_locomo(sessions, chunk_size)
    
    # å¦åˆ™æŒ‰ session è¾¹ç•Œåˆ‡åˆ†ï¼ˆåŸæœ‰é€»è¾‘ï¼Œæ¯ä¸ª session ä¸€ä¸ª chunkï¼‰
    chunks: List[str] = []
    for idx, ts, turns, ssum in sessions:
        chunks.append(session_to_text_locomo(idx, ts, turns, ssum))
    return chunks


def iter_sessions(
    data_path: Optional[str] = None,
    split: str = "test",
    limit: Optional[int] = None,
    use_locomo_format: bool = True,
    chunk_size: Optional[int] = 1000
) -> Iterator[Dict[str, Any]]:
    """
    è¿­ä»£LongMemEvalæ•°æ®é›†ä¸­çš„sessions
    
    ç»Ÿä¸€æ¥å£ï¼šè¿”å›æ ¼å¼ä¸º
    {
        "session_id": str,
        "turns": [...],           # ç»†ç²’åº¦ï¼šé€turnå¯¹è¯ï¼ˆç»™Mem0/LightMem/MIRIX/RAW+LLMç”¨ï¼‰
        "session_chunks": [...],  # ç²—ç²’åº¦ï¼šæŒ‰sessionç»„ç»‡çš„chunkï¼ˆç»™GAMç”¨ï¼‰
        "qa_pairs": [...]         # éœ€è¦å›ç­”çš„é—®é¢˜
    }
    
    å…³é”®è®¾è®¡ï¼š
    - åŒæ—¶æä¾›ä¸¤ç§ç²’åº¦çš„turnsï¼Œè®©ä¸åŒç³»ç»Ÿé€‰æ‹©æœ€é€‚åˆè‡ªå·±çš„ç²’åº¦
    - ç³»ç»Ÿå¯ä»¥é€šè¿‡preferred_turns_keyå±æ€§æŒ‡å®šä½¿ç”¨å“ªä¸ªç²’åº¦
    - GAMä½¿ç”¨"session_chunks"ï¼ˆç²—ç²’åº¦ï¼‰ï¼Œå…¶ä»–ç³»ç»Ÿä½¿ç”¨"turns"ï¼ˆç»†ç²’åº¦ï¼‰
    - æ”¯æŒè‡ªåŠ¨æ£€æµ‹æ•°æ®æ ¼å¼ï¼šå¦‚æœæ˜¯åŸå§‹ LongMemEval æ ¼å¼ï¼Œä¼šè‡ªåŠ¨è½¬æ¢ä¸º LoCoMo æ ¼å¼å¤„ç†
    - å¦‚æœ use_locomo_format=Trueï¼Œä¼šå…ˆè½¬æ¢ä¸º LoCoMo æ ¼å¼ï¼Œç„¶åæŒ‰ç…§ locomo.py çš„æ–¹å¼å¤„ç†
    - å¦‚æœæŒ‡å®š chunk_sizeï¼Œsession_chunks å°†æŒ‰ token æ•°é‡åˆ‡åˆ†ï¼Œè€Œä¸æ˜¯æŒ‰ session è¾¹ç•Œ
    
    Args:
        data_path: æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨ ./data/LongMemEval/longmemeval_s_cleaned.json
        split: æ•°æ®é›†splitï¼ˆLongMemEvalé€šå¸¸åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼‰
        limit: é™åˆ¶è¿”å›çš„æ ·æœ¬æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        use_locomo_format: å¦‚æœä¸º Trueï¼Œä¼šå°†åŸå§‹æ ¼å¼è½¬æ¢ä¸º LoCoMo æ ¼å¼åå¤„ç†ï¼ˆå‚è€ƒ locomo.pyï¼‰
        chunk_size: å¦‚æœæä¾›ï¼Œsession_chunks å°†æŒ‰æ­¤ token æ•°é‡åˆ‡åˆ†ï¼›å¦‚æœä¸º Noneï¼ŒæŒ‰ session è¾¹ç•Œåˆ‡åˆ†
        
    Yields:
        Sessionå­—å…¸ï¼ŒåŒ…å«turnså’Œsession_chunksä¸¤ç§ç²’åº¦çš„æ•°æ®
    """
    if data_path is None:
        data_path = "./data/LongMemEval/longmemeval_s_cleaned.json"
    
    if not Path(data_path).exists():
        raise FileNotFoundError(f"LongMemEval data file not found: {data_path}")
    
    samples = load_longmemeval_json(data_path)
    
    if limit:
        samples = samples[:limit]
    
    # æ£€æµ‹ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼ï¼Œå¹¶å†³å®šæ˜¯å¦éœ€è¦è½¬æ¢
    converted_to_locomo = False
    if samples:
        is_locomo = _is_locomo_format(samples[0])
        if not is_locomo and use_locomo_format:
            # è½¬æ¢ä¸º LoCoMo æ ¼å¼ï¼ˆåœ¨å†…å­˜ä¸­ï¼‰
            print(f"ğŸ”„ æ£€æµ‹åˆ°åŸå§‹ LongMemEval æ ¼å¼ï¼Œæ­£åœ¨è½¬æ¢ä¸º LoCoMo æ ¼å¼...")
            samples = convert_to_locomo_style(samples)
            print(f"âœ… è½¬æ¢å®Œæˆï¼Œå…± {len(samples)} æ¡æ•°æ®")
            converted_to_locomo = True
            is_locomo = True  # è½¬æ¢åéƒ½æ˜¯ LoCoMo æ ¼å¼
    
    for sample_idx, sample in enumerate(samples):
        # å¦‚æœå·²ç»è½¬æ¢è¿‡ï¼Œæ‰€æœ‰æ ·æœ¬éƒ½æ˜¯ LoCoMo æ ¼å¼ï¼›å¦åˆ™æ£€æµ‹å½“å‰æ ·æœ¬çš„æ ¼å¼
        if converted_to_locomo:
            is_locomo = True
        else:
            is_locomo = _is_locomo_format(sample)
        
        if is_locomo:
            # LoCoMo æ ¼å¼å¤„ç†ï¼ˆå‚è€ƒ locomo.pyï¼‰
            # ä» qa ä¸­è·å– question_id ä½œä¸º session_idï¼ˆä½¿ç”¨åŸæ¥çš„ question_idï¼‰
            qa_list = sample.get("qa", [])
            question_id = None
            if qa_list and len(qa_list) > 0:
                question_id = qa_list[0].get("question_id", None)
            
            # å¦‚æœæ²¡æœ‰ question_idï¼Œå°è¯•ä½¿ç”¨ sample_id æˆ–ç”Ÿæˆé»˜è®¤å€¼
            if not question_id:
                question_id = sample.get("sample_id", f"question_{sample_idx}")
            
            conv = sample.get("conversation", {})
            sessions_meta = extract_sessions(conv)
            
            # 1. æ„é€ session_chunksï¼ˆç²—ç²’åº¦ï¼Œç»™GAMç”¨ï¼‰
            session_chunks = build_session_chunks_for_locomo_sample(sample, chunk_size=chunk_size)
            # è½¬æ¢ä¸ºpseudo-turnsæ ¼å¼ï¼Œæ¯ä¸ªchunkä½œä¸ºä¸€ä¸ªturn
            session_chunks_turns = []
            for chunk_idx, chunk_text in enumerate(session_chunks):
                session_chunks_turns.append({
                    "speaker": "system",  # æ ‡è®°ä¸ºç³»ç»Ÿæ„é€ çš„sessionå—
                    "text": chunk_text,   # å®Œæ•´çš„session_chunkæ–‡æœ¬
                    "timestamp": None,    # timestampå·²åœ¨chunkæ–‡æœ¬ä¸­
                    "chunk_idx": chunk_idx
                })
            
            # 2. æ„é€ ç»†ç²’åº¦turnsï¼ˆç»™Mem0/LightMem/MIRIX/RAW+LLMç”¨ï¼‰
            fine_grain_turns = []
            for idx, ts, turns, ssum in sessions_meta:
                for turn in turns:
                    blip_caption = turn.get("blip_caption", "")
                    text = turn.get("text", "")
                    if blip_caption:
                        text = f"(blip_caption: {blip_caption}) text:{text} "
                    else:
                        text = text
                    fine_grain_turns.append({
                        "speaker": turn.get("speaker", "Unknown"),
                        "text": text,
                        "timestamp": ts,
                        "dia_id": turn.get("dia_id", ""),
                        "session_idx": idx
                    })
            
            # 3. æ”¶é›†QA pairs
            qa_pairs = []
            for qa_idx, qa in enumerate(qa_list):
                category = qa.get("category")
                # æ³¨æ„ï¼šLongMemEval æ²¡æœ‰ category==5 çš„è¿‡æ»¤è§„åˆ™
                qa_question_id = qa.get("question_id", question_id)
                qa_pairs.append({
                    "query_id": qa_question_id,
                    "question": qa.get("question", ""),
                    "ground_truth": qa.get("answer", ""),
                    "category": category,
                    "evidence": qa.get("evidence", []),
                    "meta": {
                        "sample_id": sample.get("sample_id", question_id),
                        "qa_index": qa_idx,
                        "category": category,
                        "question_id": qa_question_id
                    }
                })
            
            # è¿”å›æ ¼å¼ï¼šåŒæ—¶æä¾›ä¸¤ç§ç²’åº¦çš„turns
            yield {
                "session_id": question_id,  # ä½¿ç”¨åŸæ¥çš„ question_id
                "turns": fine_grain_turns,           # ç»†ç²’åº¦ï¼šé€å¥å¯¹è¯
                "session_chunks": session_chunks_turns,  # ç²—ç²’åº¦ï¼šGAMçš„session_chunk
                "qa_pairs": qa_pairs,
                "meta": {
                    "question_id": question_id,  # æ·»åŠ  question_id åˆ° meta
                    "num_sessions": len(sessions_meta),
                    "num_fine_turns": len(fine_grain_turns),
                    "num_chunks": len(session_chunks_turns),
                    "num_qa": len(qa_pairs)
                }
            }
        else:
            # åŸå§‹ LongMemEval æ ¼å¼å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            question_id = sample.get("question_id", f"question_{sample_idx}")
            question_type = sample.get("question_type", "unknown")
            question = sample.get("question", "")
            question_date = sample.get("question_date", "")
            answer = sample.get("answer", "")
            answer_session_ids = sample.get("answer_session_ids", [])
            
            haystack_dates = sample.get("haystack_dates", [])
            haystack_session_ids = sample.get("haystack_session_ids", [])
            haystack_sessions = sample.get("haystack_sessions", [])
            
            # 1. æ„é€ session_chunksï¼ˆç²—ç²’åº¦ï¼Œç»™GAMç”¨ï¼‰
            session_chunks = build_session_chunks_for_sample(sample, chunk_size=chunk_size)
            # è½¬æ¢ä¸ºpseudo-turnsæ ¼å¼ï¼Œæ¯ä¸ªchunkä½œä¸ºä¸€ä¸ªturn
            session_chunks_turns = []
            for chunk_idx, (chunk_text, session_id, session_date) in enumerate(
                zip(session_chunks, haystack_session_ids, haystack_dates)
            ):
                session_chunks_turns.append({
                    "speaker": "system",  # æ ‡è®°ä¸ºç³»ç»Ÿæ„é€ çš„sessionå—
                    "text": chunk_text,   # å®Œæ•´çš„session_chunkæ–‡æœ¬
                    "timestamp": session_date,
                    "session_id": session_id,
                    "chunk_idx": chunk_idx
                })
            
            # 2. æ„é€ ç»†ç²’åº¦turnsï¼ˆç»™Mem0/LightMem/MIRIX/RAW+LLMç”¨ï¼‰
            # é¦–å…ˆæ ‡è®°å“ªäº›sessionåŒ…å«ç­”æ¡ˆï¼ˆå‚è€ƒEverMemOSçš„å®ç°ï¼‰
            evidence_session_idx = []
            for idx, session_id in enumerate(haystack_session_ids):
                if session_id in answer_session_ids:
                    evidence_session_idx.append(idx)
            
            fine_grain_turns = []
            evidence = []  # æ”¶é›†evidenceä¿¡æ¯ï¼Œæ ¼å¼ä¸º "D{session_idx}:{turn_idx}"
            
            for session_idx, (session_date, session_id, session_entry) in enumerate(
                zip(haystack_dates, haystack_session_ids, haystack_sessions)
            ):
                if not isinstance(session_entry, list):
                    session_entry = [session_entry]
                
                # æ ‡è®°å½“å‰sessionæ˜¯å¦åŒ…å«ç­”æ¡ˆ
                session_has_answer = session_idx in evidence_session_idx
                
                for turn_idx, turn in enumerate(session_entry):
                    role = turn.get("role", "unknown")
                    content = turn.get("content", "")
                    
                    # æ£€æŸ¥å½“å‰turnæ˜¯å¦åŒ…å«ç­”æ¡ˆï¼ˆå¦‚æœsessionåŒ…å«ç­”æ¡ˆï¼Œåˆ™æ ‡è®°ï¼‰
                    # æ³¨æ„ï¼šLongMemEvalåŸå§‹æ•°æ®å¯èƒ½æ²¡æœ‰turnçº§åˆ«çš„has_answeræ ‡è®°
                    # è¿™é‡Œæˆ‘ä»¬åŸºäºsessionçº§åˆ«æ¥æ ‡è®°
                    has_answer = session_has_answer
                    
                    # å¦‚æœåŸå§‹æ•°æ®ä¸­æœ‰has_answerå­—æ®µï¼Œä½¿ç”¨å®ƒ
                    if "has_answer" in turn:
                        has_answer = turn["has_answer"]
                    
                    # å¦‚æœåŒ…å«ç­”æ¡ˆï¼Œæ·»åŠ åˆ°evidenceåˆ—è¡¨
                    if has_answer:
                        evidence.append(f"D{session_idx}:{turn_idx}")
                    
                    fine_grain_turns.append({
                        "speaker": role,
                        "text": content,
                        "timestamp": session_date,
                        "session_id": session_id,
                        "session_idx": session_idx,
                        "turn_idx": turn_idx,
                        "has_answer": has_answer,  # æ ‡è®°æ˜¯å¦åŒ…å«ç­”æ¡ˆ
                        "dia_id": f"D{session_idx}:{turn_idx}"  # æ·»åŠ dia_idï¼Œä¸EverMemOSæ ¼å¼ä¸€è‡´
                    })
            
            # 3. æ”¶é›†QA pairsï¼ˆå‚è€ƒEverMemOSçš„å®ç°ï¼Œæ·»åŠ evidenceä¿¡æ¯ï¼‰
            # ç¡®ä¿answerè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå› ä¸ºæœ‰äº›ç­”æ¡ˆæ˜¯æ•´æ•°ï¼‰
            answer_str = str(answer) if answer is not None else ""
            
            qa_pairs = [{
                "query_id": question_id,
                "question": question,
                "ground_truth": answer_str,  # ç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                "question_type": question_type,
                "question_date": question_date,
                "answer_session_ids": answer_session_ids,
                "evidence": evidence,  # æ·»åŠ evidenceåˆ—è¡¨
                "category": question_type,  # ä½¿ç”¨question_typeä½œä¸ºcategory
                "meta": {
                    "question_id": question_id,
                    "question_type": question_type,
                    "question_date": question_date,
                    "evidence_session_indices": evidence_session_idx,
                    "original_answer": answer  # ä¿ç•™åŸå§‹ç­”æ¡ˆï¼ˆå¯èƒ½æ˜¯intæˆ–strï¼‰
                }
            }]
            
            # è¿”å›æ ¼å¼ï¼šåŒæ—¶æä¾›ä¸¤ç§ç²’åº¦çš„turns
            yield {
                "session_id": question_id,
                "turns": fine_grain_turns,           # ç»†ç²’åº¦ï¼šé€turnå¯¹è¯
                "session_chunks": session_chunks_turns,  # ç²—ç²’åº¦ï¼šæŒ‰sessionç»„ç»‡çš„chunk
                "qa_pairs": qa_pairs,
                "meta": {
                    "question_id": question_id,
                    "question_type": question_type,
                    "num_sessions": len(haystack_sessions),
                    "num_fine_turns": len(fine_grain_turns),
                    "num_chunks": len(session_chunks_turns),
                    "num_qa": len(qa_pairs)
                }
            }


def convert_time_format(input_str: str) -> str:
    """
    è½¬æ¢æ—¶é—´æ ¼å¼ï¼šä» "YYYY/MM/DD (Day) HH:MM" è½¬æ¢ä¸º "H:MM am/pm on D Month, YYYY"
    
    å‚è€ƒ EverMemOS å®ç°ï¼š
    - è¾“å…¥æ ¼å¼: %Y/%m/%d (%a) %H:%M
    - è¾“å‡ºæ ¼å¼: %-I:%M %p on %-d %B, %Y (ç„¶åè½¬æ¢ä¸ºå°å†™å¹¶é¦–å­—æ¯å¤§å†™æœˆä»½)
    
    Args:
        input_str: è¾“å…¥æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "2023/03/15 (Wed) 14:30"
        
    Returns:
        è½¬æ¢åçš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "2:30 pm on 15 March, 2023"
    """
    # è¾“å…¥æ ¼å¼: %Y: year, %m: month, %d: day, %a: weekday abbr, %H: 24-hour, %M: minute
    input_format = "%Y/%m/%d (%a) %H:%M"
    
    try:
        # è§£æè¾“å…¥å­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡
        dt_object = datetime.strptime(input_str, input_format)
        
        # è¾“å‡ºæ ¼å¼: %-I: 12-hour (no leading zero), %M: minute, %p: AM/PM, 
        #           %-d: day (no leading zero), %B: full month name, %Y: year
        # æ³¨æ„ï¼šPythonçš„strftimeä¸æ”¯æŒ%-Iå’Œ%-dï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†
        hour_12 = dt_object.hour % 12
        if hour_12 == 0:
            hour_12 = 12
        am_pm = "am" if dt_object.hour < 12 else "pm"
        day = dt_object.day
        month = dt_object.strftime("%B")
        year = dt_object.year
        
        # æ ¼å¼åŒ–ï¼šH:MM am/pm on D Month, YYYY
        formatted_string = f"{hour_12}:{dt_object.minute:02d} {am_pm} on {day} {month}, {year}"
        
        return formatted_string
    except ValueError as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
        print(f"Warning: Failed to parse time format '{input_str}': {e}")
        return input_str


def convert_to_locomo_style(
    lmeval_data: List[Dict[str, Any]],
    output_path: Optional[str] = None
) -> List[Dict[str, Any]]:
    """
    å°† LongMemEval æ ¼å¼è½¬æ¢ä¸º LoCoMo æ ¼å¼
    
    å‚è€ƒ EverMemOS å®ç° (longmemeval_converter.py)
    
    è½¬æ¢è¦ç‚¹ï¼š
    1. æ—¶é—´æ ¼å¼è½¬æ¢ï¼šä» "YYYY/MM/DD (Day) HH:MM" è½¬æ¢ä¸º "H:MM am/pm on D Month, YYYY"
    2. å¯¹è¯ç»“æ„ï¼šå°† haystack_sessions è½¬æ¢ä¸º LoCoMo çš„ conversation æ ¼å¼
       - conversation["session_0"], conversation["session_0_date_time"], ...
    3. QA ç»“æ„ï¼šè½¬æ¢ä¸º LoCoMo çš„ qa æ ¼å¼
       - åŒ…å« question_id, question, answer, evidence, category
    4. Speaker å‘½åï¼šä¸ºæ¯ä¸ª speaker æ·»åŠ  question_id åç¼€
    5. Evidence æ ‡è®°ï¼šç”Ÿæˆ dia_id æ ¼å¼ä¸º D{session_idx}:{turn_idx}
    
    Args:
        lmeval_data: LongMemEval åŸå§‹æ•°æ®åˆ—è¡¨
        output_path: å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜è½¬æ¢åçš„æ•°æ®åˆ°æ–‡ä»¶
        
    Returns:
        LoCoMo æ ¼å¼çš„æ•°æ®åˆ—è¡¨
    """
    locomo_style_data = []
    
    for data in lmeval_data:
        data_dict = {
            "qa": [],
            "conversation": {}
        }
        
        question_id = data.get("question_id", "")
        
        # æ‰¾åˆ°åŒ…å«ç­”æ¡ˆçš„ session ç´¢å¼•
        evidence_session_idx = []
        haystack_session_ids = data.get("haystack_session_ids", [])
        answer_session_ids = data.get("answer_session_ids", [])
        
        for idx, session_id in enumerate(haystack_session_ids):
            if session_id in answer_session_ids:
                evidence_session_idx.append(idx)
        
        # æ ‡è®°åŒ…å«ç­”æ¡ˆçš„æ¶ˆæ¯
        haystack_sessions = data.get("haystack_sessions", [])
        for idx, session in enumerate(haystack_sessions):
            if not isinstance(session, list):
                session = [session]
            for i, msg in enumerate(session):
                # æ ‡è®°å½“å‰æ¶ˆæ¯æ˜¯å¦åŒ…å«ç­”æ¡ˆ
                msg["has_answer"] = idx in evidence_session_idx
                # å¦‚æœåŸå§‹æ•°æ®ä¸­æœ‰ has_answer å­—æ®µï¼Œä½¿ç”¨å®ƒ
                if "has_answer" in msg:
                    # å·²ç»è®¾ç½®ï¼Œä¿æŒåŸå€¼
                    pass
        
        # æ”¶é›† evidenceï¼ˆæ ¼å¼ï¼šD{session_idx}:{turn_idx}ï¼‰
        evidence = []
        for idx, session in enumerate(haystack_sessions):
            if not isinstance(session, list):
                session = [session]
            for i, msg in enumerate(session):
                if msg.get("has_answer", False):
                    evidence.append(f"D{idx}:{i}")
        
        # æ„å»º QA
        answer = data.get("answer", "")
        # ç¡®ä¿ answer è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆå› ä¸ºæœ‰äº›ç­”æ¡ˆæ˜¯æ•´æ•°ï¼‰
        answer_str = str(answer) if answer is not None else ""
        
        data_dict["qa"].append({
            "question_id": question_id,
            "question": data.get("question", ""),
            "answer": answer_str,
            "evidence": evidence,
            "category": data.get("question_type", "unknown")
        })
        
        # æ„å»º conversation
        data_dict["conversation"]["speaker_a"] = f"user_{question_id}"
        data_dict["conversation"]["speaker_b"] = f"assistant_{question_id}"
        
        haystack_dates = data.get("haystack_dates", [])
        for idx, session in enumerate(haystack_sessions):
            # è½¬æ¢æ—¶é—´æ ¼å¼
            session_date = haystack_dates[idx] if idx < len(haystack_dates) else ""
            converted_date = convert_time_format(session_date) if session_date else ""
            
            # è®¾ç½® session æ—¥æœŸæ—¶é—´
            data_dict["conversation"][f"session_{idx}_date_time"] = converted_date
            
            # è®¾ç½® session å†…å®¹
            session_key = f"session_{idx}"
            data_dict["conversation"][session_key] = []
            
            if not isinstance(session, list):
                session = [session]
            
            for i, msg in enumerate(session):
                role = msg.get("role", "unknown")
                content = msg.get("content", "")
                
                data_dict["conversation"][session_key].append({
                    "speaker": f"{role}_{question_id}",
                    "text": content,
                    "dia_id": f"D{idx}:{i}"
                })
        
        locomo_style_data.append(data_dict)
    
    # å¦‚æœæä¾›äº†è¾“å‡ºè·¯å¾„ï¼Œä¿å­˜æ–‡ä»¶
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(locomo_style_data, f, indent=2, ensure_ascii=False)
        print(f"âœ… å·²ä¿å­˜ {len(locomo_style_data)} æ¡è½¬æ¢åçš„æ•°æ®åˆ°: {output_path}")
    
    return locomo_style_data


if __name__ == "__main__":
    import sys
    

        # é»˜è®¤æµ‹è¯•æ¨¡å¼ï¼šæµ‹è¯•æ•°æ®åŠ è½½å™¨
    print("Testing LongMemEval data loader...")
    count = 0
    for session in iter_sessions():
        count += 1
        print(f"\nSession {count}:")
        print(f"  session_id: {session['session_id']}")
        print(f"  question_type: {session['meta'].get('question_type', 'unknown')}")
        print(f"  num_turns (fine-grain): {len(session['turns'])}")
        print(f"  num_session_chunks (coarse-grain): {len(session.get('session_chunks', []))}")
        print(f"  num_qa_pairs: {len(session['qa_pairs'])}")
        if session['turns']:
            first_turn = session['turns'][0]
            print(f"  first fine-grain turn: {first_turn['speaker']}: {first_turn['text'][:80]}...")
        if session.get('session_chunks'):
            first_chunk = session['session_chunks'][0]
            print(f"  first session_chunk: {first_chunk['speaker']}: {first_chunk['text'][:80]}...")
        if session['qa_pairs']:
            qa = session['qa_pairs'][0]
            print(f"  question: {qa['question']}")
            # å®‰å…¨å¤„ç†ground_truthï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼‰
            ground_truth = qa['ground_truth']
            if isinstance(ground_truth, str):
                print(f"  answer: {ground_truth[:80]}...")
            else:
                print(f"  answer: {ground_truth}")
        
        # ä¿å­˜ç¤ºä¾‹åˆ°ä¸´æ—¶ç›®å½•
        os.makedirs("./core/datasets/tmp_longmemeval", exist_ok=True)
        with open(f"./core/datasets/tmp_longmemeval/{session['session_id']}.json", "w", encoding='utf-8') as f:
            json.dump(session, f, indent=4, ensure_ascii=False)
    
    print(f"\nTotal sessions: {count}")
    print("\nğŸ’¡ æç¤º: ä½¿ç”¨ 'python longmemeval.py convert [input_path] [output_path]' æ¥è½¬æ¢æ•°æ®ä¸º LoCoMo æ ¼å¼")

